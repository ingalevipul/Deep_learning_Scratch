{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation for Regression – Annotated Notebook\n",
    "This notebook demonstrates how to implement manual backpropagation for a simple regression problem using NumPy. We will:\n",
    "- Generate synthetic data\n",
    "- Initialize parameters\n",
    "- Perform forward and backward passes\n",
    "- Update weights manually\n",
    "- Train the network and predict values\n",
    "\n",
    "Created by-Vipul Ingale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 – Import Libraries\n",
    "We import:\n",
    "- **NumPy** for numerical computations\n",
    "- **Pandas** for tabular data handling\n",
    "- **warnings** to suppress library warnings for cleaner output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 – Create a Synthetic Dataset\n",
    "We generate:\n",
    "- 20 random samples\n",
    "- **CGPA** between 5.0 and 10.0 (2 decimals)\n",
    "- **Profile score** between 6 and 15 (integers)\n",
    "- **LPA** = `0.5 * CGPA + 0.3 * Profile_score + noise` (noise from normal distribution)\n",
    "Finally, store the data in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cgpa  profile_score   lpa\n",
      "0   6.87             15  7.56\n",
      "1   9.75              8  6.89\n",
      "2   8.66             12  8.40\n",
      "3   7.99              9  7.48\n",
      "4   5.78             14  6.91\n",
      "5   5.78              8  5.48\n",
      "6   5.29             10  5.04\n",
      "7   9.33              8  6.86\n",
      "8   8.01             12  7.38\n",
      "9   8.54             10  8.03\n",
      "10  5.10             14  6.91\n",
      "11  9.85             12  7.82\n",
      "12  9.16              7  5.59\n",
      "13  6.06              9  5.21\n",
      "14  5.91             14  7.24\n",
      "15  5.92              7  5.22\n",
      "16  6.52             15  8.13\n",
      "17  7.62             14  7.09\n",
      "18  7.16             15  8.36\n",
      "19  6.46             10  6.24\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "num_samples = 20\n",
    "cgpa = np.round(np.random.uniform(5.0, 10.0, num_samples), 2)\n",
    "profile_score = np.random.randint(6, 16, num_samples)\n",
    "noise = np.round(np.random.normal(0, 0.5, num_samples), 2)\n",
    "lpa = np.round(0.5 * cgpa + 0.3 * profile_score + noise, 2)\n",
    "df = pd.DataFrame({\n",
    "    'cgpa': cgpa,\n",
    "    'profile_score': profile_score,\n",
    "    'lpa': lpa\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 – Parameter Initialization\n",
    "Function to initialize neural network parameters given layer dimensions (`layer_dims`).\n",
    "- Weights `W` start at 0.1\n",
    "- Biases `b` start at 0\n",
    "- Returns a dictionary of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.ones((layer_dims[l-1], layer_dims[l])) * 0.1\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Initializing for [2,2,1]\n",
    "This means:\n",
    "- 2 input neurons\n",
    "- 2 hidden neurons\n",
    "- 1 output neuron\n",
    "\n",
    "\n",
    "for understanding purpose,we are creating NN with only 1 hidden layer\n",
    "- parameter W1 represents [[W11,W12],[W21,W22]]\n",
    "- parameter b1 represents bais for hidden layer and b2 for output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.1, 0.1],\n",
       "        [0.1, 0.1]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[0.1],\n",
       "        [0.1]]),\n",
       " 'b2': array([[0.]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_parameters([2,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 – Linear Function\n",
    "Computes:\n",
    "$$\n",
    "Z = W^T A_{prev} + b\n",
    "$$\n",
    "\n",
    "- A_prev is basically output from prev layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_func(A_prev, W, b):\n",
    "    Z = np.dot(W.T, A_prev) + b\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 – Forward Pass\n",
    "Iteratively applies the linear function for each layer.\n",
    "Returns the final output and the activations from the last hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X, parameters):\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    for l in range(1, L+1):\n",
    "        A_prev = A\n",
    "        Wl = parameters['W' + str(l)]\n",
    "        bl = parameters['b' + str(l)]\n",
    "        A = Linear_func(A_prev, Wl, bl)\n",
    "    return A, A_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 – Single Example Forward Pass\n",
    "We take the first row from the dataset and make a forward pass with initial parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[0].reshape(2,1)\n",
    "y = df[['lpa']].values[0][0]\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "y_hat, A1 = forward_pass(X, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 – Flatten Prediction\n",
    "Get a scalar value instead of a nested array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = y_hat[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 – View Hidden Layer Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.187],\n",
       "       [2.187]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 – Compare Actual vs Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(7.56), np.float64(0.43740000000000007))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 – Inspect Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.1, 0.1],\n",
       "        [0.1, 0.1]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[0.1],\n",
       "        [0.1]]),\n",
       " 'b2': array([[0.]])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11 – Update Parameters (Manual Backpropagation)\n",
    "Uses derivatives of MSE loss to update the weights manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, y, y_hat, A1, X, L):\n",
    "    parameters['W2'][0][0] += (L * 2 * (y - y_hat) * A1[0][0])\n",
    "    parameters['W2'][1][0] += (L * 2 * (y - y_hat) * A1[1][0])\n",
    "    parameters['b2'][0][0] += (L * 2 * (y - y_hat))\n",
    "\n",
    "    parameters['W1'][0][0] += (L * 2 * (y - y_hat) * parameters['W2'][0][0] * X[0][0])\n",
    "    parameters['W1'][0][1] += (L * 2 * (y - y_hat) * parameters['W2'][0][0] * X[1][0])\n",
    "    parameters['b1'][0][0] += (L * 2 * (y - y_hat) * parameters['W2'][0][0])\n",
    "\n",
    "    parameters['W1'][1][0] += (L * 2 * (y - y_hat) * parameters['W2'][1][0] * X[0][0])\n",
    "    parameters['W1'][1][1] += (L * 2 * (y - y_hat) * parameters['W2'][1][0] * X[1][0])\n",
    "    parameters['b1'][1][0] += (L * 2 * (y - y_hat) * parameters['W2'][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12 – Training Loop\n",
    "Randomly selects samples each iteration, runs forward pass, updates weights, and prints loss per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 Loss - 13.328097973710246\n",
      "Epoch - 2 Loss - 0.19289568020544223\n",
      "Epoch - 3 Loss - 0.4411186461839799\n",
      "Epoch - 4 Loss - 0.40780316581811593\n",
      "Epoch - 5 Loss - 0.21300332646743594\n",
      "Epoch - 6 Loss - 0.302362853773904\n",
      "Epoch - 7 Loss - 0.2488150936830443\n",
      "Epoch - 8 Loss - 0.3740165476995419\n",
      "Epoch - 9 Loss - 0.31586229369334773\n",
      "Epoch - 10 Loss - 0.5071108860392458\n",
      "Epoch - 11 Loss - 0.5262693479836422\n",
      "Epoch - 12 Loss - 0.4288874502614931\n",
      "Epoch - 13 Loss - 0.22274858443195567\n",
      "Epoch - 14 Loss - 0.2589400435100473\n",
      "Epoch - 15 Loss - 0.49958209879101806\n",
      "Epoch - 16 Loss - 0.37675618399297356\n",
      "Epoch - 17 Loss - 0.40754506345339864\n",
      "Epoch - 18 Loss - 0.3744376761838866\n",
      "Epoch - 19 Loss - 0.40344540203633994\n",
      "Epoch - 20 Loss - 0.40438064164634835\n",
      "Epoch - 21 Loss - 0.33650086212018526\n",
      "Epoch - 22 Loss - 0.40220069086189075\n",
      "Epoch - 23 Loss - 0.3270757257127329\n",
      "Epoch - 24 Loss - 0.5394271164458627\n",
      "Epoch - 25 Loss - 0.26723452303747774\n",
      "Epoch - 26 Loss - 0.37261375754245096\n",
      "Epoch - 27 Loss - 0.48189089831270254\n",
      "Epoch - 28 Loss - 0.3850428571810231\n",
      "Epoch - 29 Loss - 0.5476285490583133\n",
      "Epoch - 30 Loss - 0.4110183856074306\n"
     ]
    }
   ],
   "source": [
    "def backpropagation_train(epochs=30, parms=[2,2,1], learning_rate=0.001):\n",
    "    parameters = initialize_parameters(parms)\n",
    "    for i in range(epochs):\n",
    "        Loss = []\n",
    "        for j in range(df.shape[0]):\n",
    "            random_ip = df.sample()\n",
    "            X = random_ip[['cgpa', 'profile_score']].values.reshape(2,1)\n",
    "            y = random_ip['lpa'].values.reshape(1,1)\n",
    "            y_hat, A1 = forward_pass(X, parameters)\n",
    "            y_hat = y_hat[0][0]\n",
    "            update_parameters(parameters, y, y_hat, A1, X, learning_rate)\n",
    "            Loss.append((y - y_hat)**2)\n",
    "        print('Epoch -', i+1, 'Loss -', np.array(Loss).mean())\n",
    "\n",
    "backpropagation_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13 – Prediction Function\n",
    "Takes new CGPA, Profile Score, and actual LPA to predict and compute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x1, x2, y):\n",
    "    X = np.array([x1, x2]).reshape(2,1)\n",
    "    y = np.array([y]).reshape(1,1)\n",
    "    Predicted, _ = forward_pass(X, parameters)\n",
    "    error = Predicted - y\n",
    "    return Predicted, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14 – Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.34]]), array([[-6.66]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(9, 8, 7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
